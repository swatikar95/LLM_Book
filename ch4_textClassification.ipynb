{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\swati\\anaconda3\\envs\\env_LLMbook\\lib\\site-packages\\huggingface_hub\\file_download.py:140: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\swati\\.cache\\huggingface\\hub\\datasets--rotten_tomatoes. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Generating train split: 100%|██████████| 8530/8530 [00:00<00:00, 544267.33 examples/s]\n",
      "Generating validation split: 100%|██████████| 1066/1066 [00:00<00:00, 256666.36 examples/s]\n",
      "Generating test split: 100%|██████████| 1066/1066 [00:00<00:00, 418292.46 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 8530\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 1066\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 1066\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load our data\n",
    "data = load_dataset(\"rotten_tomatoes\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['the rock is destined to be the 21st century\\'s new \" conan \" and that he\\'s going to make a splash even greater than arnold schwarzenegger , jean-claud van damme or steven segal .',\n",
       "  'the gorgeously elaborate continuation of \" the lord of the rings \" trilogy is so huge that a column of words cannot adequately describe co-writer/director peter jackson\\'s expanded vision of j . r . r . tolkien\\'s middle-earth .'],\n",
       " 'label': [1, 1]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"train\"][0,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Classification with representation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\swati\\anaconda3\\envs\\env_LLMbook\\lib\\site-packages\\huggingface_hub\\file_download.py:140: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\swati\\.cache\\huggingface\\hub\\models--cardiffnlp--twitter-roberta-base-sentiment-latest. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "c:\\Users\\swati\\anaconda3\\envs\\env_LLMbook\\lib\\site-packages\\transformers\\pipelines\\text_classification.py:106: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "### Using task s\n",
    "from transformers import pipeline\n",
    "\n",
    "model_path = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "pipe = pipeline(\n",
    "    model=model_path,\n",
    "    return_all_scores=True,\n",
    "    device=\"cuda\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1066it [00:02, 497.91it/s]                      \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from transformers.pipelines.pt_utils import KeyDataset\n",
    "\n",
    "#run inference\n",
    "y_pred = []\n",
    "for output in tqdm(pipe(KeyDataset(data[\"test\"], \"text\"), batch_size=16)):\n",
    "    # print(output)\n",
    "    negative_score = output[0][\"score\"]\n",
    "    positive_score = output[2][\"score\"]\n",
    "    assignment = np.argmax([negative_score, positive_score])\n",
    "    y_pred.append(assignment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 0, 1, 1, 0, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def evaluate_performance(y_true, y_pred):\n",
    "    \"\"\"Create and print the classification report\"\"\"\n",
    "    performance = classification_report(\n",
    "        y_true, y_pred,\n",
    "        target_names=[\"Negative Review\", \"Positive Review\"]\n",
    "    )\n",
    "    print(performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "Negative Review       0.76      0.88      0.81       533\n",
      "Positive Review       0.86      0.72      0.78       533\n",
      "\n",
      "       accuracy                           0.80      1066\n",
      "      macro avg       0.81      0.80      0.80      1066\n",
      "   weighted avg       0.81      0.80      0.80      1066\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_performance(data[\"test\"][\"label\"], y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Task that Leverage Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at C:\\Users\\swati\\.cache\\huggingface\\hub\\models--sentence-transformers--all-mpnet-base-v2\\snapshots\\9a3225965996d404b775526de6dbfe85d3368642\\config.json\n",
      "Model config MPNetConfig {\n",
      "  \"_name_or_path\": \"sentence-transformers/all-mpnet-base-v2\",\n",
      "  \"architectures\": [\n",
      "    \"MPNetForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"mpnet\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"transformers_version\": \"4.46.3\",\n",
      "  \"vocab_size\": 30527\n",
      "}\n",
      "\n",
      "loading weights file model.safetensors from cache at C:\\Users\\swati\\.cache\\huggingface\\hub\\models--sentence-transformers--all-mpnet-base-v2\\snapshots\\9a3225965996d404b775526de6dbfe85d3368642\\model.safetensors\n",
      "All model checkpoint weights were used when initializing MPNetModel.\n",
      "\n",
      "All the weights of MPNetModel were initialized from the model checkpoint at sentence-transformers/all-mpnet-base-v2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use MPNetModel for predictions without further training.\n",
      "loading file vocab.txt from cache at C:\\Users\\swati\\.cache\\huggingface\\hub\\models--sentence-transformers--all-mpnet-base-v2\\snapshots\\9a3225965996d404b775526de6dbfe85d3368642\\vocab.txt\n",
      "loading file tokenizer.json from cache at C:\\Users\\swati\\.cache\\huggingface\\hub\\models--sentence-transformers--all-mpnet-base-v2\\snapshots\\9a3225965996d404b775526de6dbfe85d3368642\\tokenizer.json\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at C:\\Users\\swati\\.cache\\huggingface\\hub\\models--sentence-transformers--all-mpnet-base-v2\\snapshots\\9a3225965996d404b775526de6dbfe85d3368642\\special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at C:\\Users\\swati\\.cache\\huggingface\\hub\\models--sentence-transformers--all-mpnet-base-v2\\snapshots\\9a3225965996d404b775526de6dbfe85d3368642\\tokenizer_config.json\n",
      "Batches: 100%|██████████| 267/267 [00:11<00:00, 23.42it/s]\n",
      "Batches: 100%|██████████| 34/34 [00:01<00:00, 24.31it/s]\n"
     ]
    }
   ],
   "source": [
    "#supervised classification\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "train_embeddings = model.encode(data['train']['text'],show_progress_bar=True)\n",
    "test_embeddings = model.encode(data['test']['text'],show_progress_bar=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8530, 768)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_embeddings.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(random_state=42)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Train a Logistic Regression on our train embeddings\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(train_embeddings, data[\"train\"][\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "Negative Review       0.85      0.86      0.85       533\n",
      "Positive Review       0.86      0.85      0.85       533\n",
      "\n",
      "       accuracy                           0.85      1066\n",
      "      macro avg       0.85      0.85      0.85      1066\n",
      "   weighted avg       0.85      0.85      0.85      1066\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict previously unseen instances\n",
    "y_pred = clf.predict(test_embeddings)\n",
    "evaluate_performance(data[\"test\"][\"label\"], y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What if we don't use any classification model, instead we use cosine similarity!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "      <th>768</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.014930</td>\n",
       "      <td>-0.005548</td>\n",
       "      <td>0.011995</td>\n",
       "      <td>-0.014927</td>\n",
       "      <td>0.006273</td>\n",
       "      <td>-0.003671</td>\n",
       "      <td>-0.026792</td>\n",
       "      <td>0.009564</td>\n",
       "      <td>0.006486</td>\n",
       "      <td>0.019282</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044446</td>\n",
       "      <td>-0.006567</td>\n",
       "      <td>0.004846</td>\n",
       "      <td>0.032993</td>\n",
       "      <td>-0.027030</td>\n",
       "      <td>0.026459</td>\n",
       "      <td>0.005665</td>\n",
       "      <td>-0.012956</td>\n",
       "      <td>0.001537</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.035829</td>\n",
       "      <td>-0.002350</td>\n",
       "      <td>-0.026249</td>\n",
       "      <td>0.025348</td>\n",
       "      <td>-0.011112</td>\n",
       "      <td>0.003088</td>\n",
       "      <td>-0.066249</td>\n",
       "      <td>-0.048875</td>\n",
       "      <td>-0.018407</td>\n",
       "      <td>-0.032934</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029469</td>\n",
       "      <td>-0.034689</td>\n",
       "      <td>0.032908</td>\n",
       "      <td>0.009154</td>\n",
       "      <td>0.029719</td>\n",
       "      <td>0.033257</td>\n",
       "      <td>0.005511</td>\n",
       "      <td>-0.014471</td>\n",
       "      <td>-0.020907</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.040902</td>\n",
       "      <td>0.110522</td>\n",
       "      <td>0.024601</td>\n",
       "      <td>-0.000690</td>\n",
       "      <td>0.005234</td>\n",
       "      <td>0.001776</td>\n",
       "      <td>-0.054121</td>\n",
       "      <td>0.007338</td>\n",
       "      <td>0.000782</td>\n",
       "      <td>0.032753</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002668</td>\n",
       "      <td>-0.029976</td>\n",
       "      <td>-0.031094</td>\n",
       "      <td>-0.004008</td>\n",
       "      <td>0.023225</td>\n",
       "      <td>-0.004077</td>\n",
       "      <td>0.084754</td>\n",
       "      <td>0.016156</td>\n",
       "      <td>0.025994</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.003141</td>\n",
       "      <td>0.030397</td>\n",
       "      <td>-0.018153</td>\n",
       "      <td>-0.022295</td>\n",
       "      <td>0.021435</td>\n",
       "      <td>0.019211</td>\n",
       "      <td>0.045022</td>\n",
       "      <td>0.083038</td>\n",
       "      <td>0.044163</td>\n",
       "      <td>0.053213</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015134</td>\n",
       "      <td>-0.002314</td>\n",
       "      <td>-0.008651</td>\n",
       "      <td>0.000362</td>\n",
       "      <td>-0.038151</td>\n",
       "      <td>-0.004815</td>\n",
       "      <td>0.003380</td>\n",
       "      <td>0.039602</td>\n",
       "      <td>-0.032613</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.006541</td>\n",
       "      <td>0.044168</td>\n",
       "      <td>0.029882</td>\n",
       "      <td>0.016410</td>\n",
       "      <td>0.003639</td>\n",
       "      <td>0.005672</td>\n",
       "      <td>-0.054883</td>\n",
       "      <td>0.011031</td>\n",
       "      <td>-0.038811</td>\n",
       "      <td>-0.015811</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.032514</td>\n",
       "      <td>-0.028547</td>\n",
       "      <td>-0.006436</td>\n",
       "      <td>0.007190</td>\n",
       "      <td>-0.055310</td>\n",
       "      <td>-0.044386</td>\n",
       "      <td>0.055256</td>\n",
       "      <td>0.098378</td>\n",
       "      <td>-0.002131</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8525</th>\n",
       "      <td>0.000396</td>\n",
       "      <td>0.092961</td>\n",
       "      <td>0.013449</td>\n",
       "      <td>0.008073</td>\n",
       "      <td>0.047658</td>\n",
       "      <td>0.046298</td>\n",
       "      <td>-0.062199</td>\n",
       "      <td>0.002735</td>\n",
       "      <td>0.026924</td>\n",
       "      <td>0.050474</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003101</td>\n",
       "      <td>-0.005296</td>\n",
       "      <td>0.004556</td>\n",
       "      <td>-0.003797</td>\n",
       "      <td>-0.054100</td>\n",
       "      <td>0.014604</td>\n",
       "      <td>0.072304</td>\n",
       "      <td>0.019597</td>\n",
       "      <td>-0.007351</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8526</th>\n",
       "      <td>0.061984</td>\n",
       "      <td>0.026447</td>\n",
       "      <td>0.011905</td>\n",
       "      <td>0.008043</td>\n",
       "      <td>-0.028330</td>\n",
       "      <td>0.030330</td>\n",
       "      <td>-0.045090</td>\n",
       "      <td>0.000994</td>\n",
       "      <td>-0.066630</td>\n",
       "      <td>-0.015674</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027525</td>\n",
       "      <td>0.030700</td>\n",
       "      <td>-0.005522</td>\n",
       "      <td>-0.009416</td>\n",
       "      <td>-0.052891</td>\n",
       "      <td>0.003865</td>\n",
       "      <td>-0.015289</td>\n",
       "      <td>0.001440</td>\n",
       "      <td>-0.026430</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8527</th>\n",
       "      <td>0.028653</td>\n",
       "      <td>0.026281</td>\n",
       "      <td>0.002346</td>\n",
       "      <td>-0.002681</td>\n",
       "      <td>0.035184</td>\n",
       "      <td>0.037812</td>\n",
       "      <td>-0.027434</td>\n",
       "      <td>-0.023547</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.019272</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023894</td>\n",
       "      <td>-0.058434</td>\n",
       "      <td>-0.059795</td>\n",
       "      <td>0.005341</td>\n",
       "      <td>-0.014020</td>\n",
       "      <td>-0.009184</td>\n",
       "      <td>-0.003212</td>\n",
       "      <td>0.031001</td>\n",
       "      <td>-0.014205</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8528</th>\n",
       "      <td>-0.003424</td>\n",
       "      <td>0.046733</td>\n",
       "      <td>-0.002419</td>\n",
       "      <td>-0.061851</td>\n",
       "      <td>-0.026619</td>\n",
       "      <td>-0.003960</td>\n",
       "      <td>-0.034317</td>\n",
       "      <td>-0.018882</td>\n",
       "      <td>0.025307</td>\n",
       "      <td>-0.008848</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002240</td>\n",
       "      <td>-0.022505</td>\n",
       "      <td>-0.033220</td>\n",
       "      <td>-0.015093</td>\n",
       "      <td>-0.007377</td>\n",
       "      <td>-0.000089</td>\n",
       "      <td>-0.022067</td>\n",
       "      <td>-0.058857</td>\n",
       "      <td>-0.018474</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8529</th>\n",
       "      <td>0.051500</td>\n",
       "      <td>0.042833</td>\n",
       "      <td>-0.013248</td>\n",
       "      <td>0.002150</td>\n",
       "      <td>-0.001671</td>\n",
       "      <td>0.013847</td>\n",
       "      <td>-0.058456</td>\n",
       "      <td>0.003276</td>\n",
       "      <td>0.001691</td>\n",
       "      <td>0.004600</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012011</td>\n",
       "      <td>-0.088713</td>\n",
       "      <td>-0.012456</td>\n",
       "      <td>0.005611</td>\n",
       "      <td>0.027685</td>\n",
       "      <td>0.048277</td>\n",
       "      <td>-0.003679</td>\n",
       "      <td>0.016476</td>\n",
       "      <td>0.000872</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8530 rows × 769 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6    \\\n",
       "0     0.014930 -0.005548  0.011995 -0.014927  0.006273 -0.003671 -0.026792   \n",
       "1     0.035829 -0.002350 -0.026249  0.025348 -0.011112  0.003088 -0.066249   \n",
       "2     0.040902  0.110522  0.024601 -0.000690  0.005234  0.001776 -0.054121   \n",
       "3    -0.003141  0.030397 -0.018153 -0.022295  0.021435  0.019211  0.045022   \n",
       "4     0.006541  0.044168  0.029882  0.016410  0.003639  0.005672 -0.054883   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "8525  0.000396  0.092961  0.013449  0.008073  0.047658  0.046298 -0.062199   \n",
       "8526  0.061984  0.026447  0.011905  0.008043 -0.028330  0.030330 -0.045090   \n",
       "8527  0.028653  0.026281  0.002346 -0.002681  0.035184  0.037812 -0.027434   \n",
       "8528 -0.003424  0.046733 -0.002419 -0.061851 -0.026619 -0.003960 -0.034317   \n",
       "8529  0.051500  0.042833 -0.013248  0.002150 -0.001671  0.013847 -0.058456   \n",
       "\n",
       "           7         8         9    ...       759       760       761  \\\n",
       "0     0.009564  0.006486  0.019282  ...  0.044446 -0.006567  0.004846   \n",
       "1    -0.048875 -0.018407 -0.032934  ...  0.029469 -0.034689  0.032908   \n",
       "2     0.007338  0.000782  0.032753  ...  0.002668 -0.029976 -0.031094   \n",
       "3     0.083038  0.044163  0.053213  ...  0.015134 -0.002314 -0.008651   \n",
       "4     0.011031 -0.038811 -0.015811  ... -0.032514 -0.028547 -0.006436   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "8525  0.002735  0.026924  0.050474  ... -0.003101 -0.005296  0.004556   \n",
       "8526  0.000994 -0.066630 -0.015674  ...  0.027525  0.030700 -0.005522   \n",
       "8527 -0.023547  0.000076  0.019272  ...  0.023894 -0.058434 -0.059795   \n",
       "8528 -0.018882  0.025307 -0.008848  ... -0.002240 -0.022505 -0.033220   \n",
       "8529  0.003276  0.001691  0.004600  ... -0.012011 -0.088713 -0.012456   \n",
       "\n",
       "           762       763       764       765       766       767  768  \n",
       "0     0.032993 -0.027030  0.026459  0.005665 -0.012956  0.001537  1.0  \n",
       "1     0.009154  0.029719  0.033257  0.005511 -0.014471 -0.020907  1.0  \n",
       "2    -0.004008  0.023225 -0.004077  0.084754  0.016156  0.025994  1.0  \n",
       "3     0.000362 -0.038151 -0.004815  0.003380  0.039602 -0.032613  1.0  \n",
       "4     0.007190 -0.055310 -0.044386  0.055256  0.098378 -0.002131  1.0  \n",
       "...        ...       ...       ...       ...       ...       ...  ...  \n",
       "8525 -0.003797 -0.054100  0.014604  0.072304  0.019597 -0.007351  0.0  \n",
       "8526 -0.009416 -0.052891  0.003865 -0.015289  0.001440 -0.026430  0.0  \n",
       "8527  0.005341 -0.014020 -0.009184 -0.003212  0.031001 -0.014205  0.0  \n",
       "8528 -0.015093 -0.007377 -0.000089 -0.022067 -0.058857 -0.018474  0.0  \n",
       "8529  0.005611  0.027685  0.048277 -0.003679  0.016476  0.000872  0.0  \n",
       "\n",
       "[8530 rows x 769 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "df = pd.DataFrame(np.hstack([train_embeddings,np.array(data['train']['label']).reshape(-1,1)]))\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 768)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Average the embeddings of all documents in each target label\n",
    "averaged_target_embeddiings = df.groupby(768).mean().values\n",
    "averaged_target_embeddiings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "Negative Review       0.85      0.84      0.84       533\n",
      "Positive Review       0.84      0.85      0.84       533\n",
      "\n",
      "       accuracy                           0.84      1066\n",
      "      macro avg       0.84      0.84      0.84      1066\n",
      "   weighted avg       0.84      0.84      0.84      1066\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Find the best matching embeddings between evaluation documents and target embeddings\n",
    "sim_matrix = cosine_similarity(test_embeddings,averaged_target_embeddiings)\n",
    "y_pred = np.argmax(sim_matrix,axis=1)\n",
    "evaluate_performance(data['test']['label'],y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zero-Shot Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create embeddings for our labels\n",
    "label_embeddings = model.encode([\"negative\",\"positive\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1066,)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "sim_matrix = cosine_similarity(test_embeddings,label_embeddings)\n",
    "y_pred = np.argmax(sim_matrix,axis=1)\n",
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "Negative Review       0.62      0.71      0.66       533\n",
      "Positive Review       0.66      0.56      0.61       533\n",
      "\n",
      "       accuracy                           0.64      1066\n",
      "      macro avg       0.64      0.64      0.64      1066\n",
      "   weighted avg       0.64      0.64      0.64      1066\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_performance(data[\"test\"][\"label\"], y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification with Generative Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\swati\\anaconda3\\envs\\env_LLMbook\\lib\\site-packages\\huggingface_hub\\file_download.py:140: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\swati\\.cache\\huggingface\\hub\\models--google--flan-t5-small. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "loading configuration file config.json from cache at C:\\Users\\swati\\.cache\\huggingface\\hub\\models--google--flan-t5-small\\snapshots\\0fc9ddf78a1e988dac52e2dac162b0ede4fd74ab\\config.json\n",
      "Model config T5Config {\n",
      "  \"_name_or_path\": \"google/flan-t5-small\",\n",
      "  \"architectures\": [\n",
      "    \"T5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 1024,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 8,\n",
      "  \"num_heads\": 6,\n",
      "  \"num_layers\": 8,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 200,\n",
      "      \"min_length\": 30,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"summarize: \"\n",
      "    },\n",
      "    \"translation_en_to_de\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to German: \"\n",
      "    },\n",
      "    \"translation_en_to_fr\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to French: \"\n",
      "    },\n",
      "    \"translation_en_to_ro\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to Romanian: \"\n",
      "    }\n",
      "  },\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"transformers_version\": \"4.46.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at C:\\Users\\swati\\.cache\\huggingface\\hub\\models--google--flan-t5-small\\snapshots\\0fc9ddf78a1e988dac52e2dac162b0ede4fd74ab\\config.json\n",
      "Model config T5Config {\n",
      "  \"_name_or_path\": \"google/flan-t5-small\",\n",
      "  \"architectures\": [\n",
      "    \"T5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 1024,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 8,\n",
      "  \"num_heads\": 6,\n",
      "  \"num_layers\": 8,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 200,\n",
      "      \"min_length\": 30,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"summarize: \"\n",
      "    },\n",
      "    \"translation_en_to_de\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to German: \"\n",
      "    },\n",
      "    \"translation_en_to_fr\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to French: \"\n",
      "    },\n",
      "    \"translation_en_to_ro\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to Romanian: \"\n",
      "    }\n",
      "  },\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"transformers_version\": \"4.46.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "loading weights file model.safetensors from cache at C:\\Users\\swati\\.cache\\huggingface\\hub\\models--google--flan-t5-small\\snapshots\\0fc9ddf78a1e988dac52e2dac162b0ede4fd74ab\\model.safetensors\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0\n",
      "}\n",
      "\n",
      "All model checkpoint weights were used when initializing T5ForConditionalGeneration.\n",
      "\n",
      "All the weights of T5ForConditionalGeneration were initialized from the model checkpoint at google/flan-t5-small.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use T5ForConditionalGeneration for predictions without further training.\n",
      "loading configuration file generation_config.json from cache at C:\\Users\\swati\\.cache\\huggingface\\hub\\models--google--flan-t5-small\\snapshots\\0fc9ddf78a1e988dac52e2dac162b0ede4fd74ab\\generation_config.json\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0\n",
      "}\n",
      "\n",
      "loading file spiece.model from cache at C:\\Users\\swati\\.cache\\huggingface\\hub\\models--google--flan-t5-small\\snapshots\\0fc9ddf78a1e988dac52e2dac162b0ede4fd74ab\\spiece.model\n",
      "loading file tokenizer.json from cache at C:\\Users\\swati\\.cache\\huggingface\\hub\\models--google--flan-t5-small\\snapshots\\0fc9ddf78a1e988dac52e2dac162b0ede4fd74ab\\tokenizer.json\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at C:\\Users\\swati\\.cache\\huggingface\\hub\\models--google--flan-t5-small\\snapshots\\0fc9ddf78a1e988dac52e2dac162b0ede4fd74ab\\special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at C:\\Users\\swati\\.cache\\huggingface\\hub\\models--google--flan-t5-small\\snapshots\\0fc9ddf78a1e988dac52e2dac162b0ede4fd74ab\\tokenizer_config.json\n"
     ]
    }
   ],
   "source": [
    "#encoder-decoder model\n",
    "pipe = pipeline(\n",
    "    \"text2text-generation\",\n",
    "    model=\"google/flan-t5-small\",\n",
    "    device=\"cuda\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 8530/8530 [00:00<00:00, 30279.43 examples/s]\n",
      "Map: 100%|██████████| 1066/1066 [00:00<00:00, 21336.71 examples/s]\n",
      "Map: 100%|██████████| 1066/1066 [00:00<00:00, 19585.39 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label', 't5'],\n",
       "        num_rows: 8530\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label', 't5'],\n",
       "        num_rows: 1066\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label', 't5'],\n",
       "        num_rows: 1066\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"Is the following sentence positive or negative?\"\n",
    "data = data.map(lambda x: {\"t5\": prompt + x[\"text\"]})\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1066 [00:00<?, ?it/s]c:\\Users\\swati\\anaconda3\\envs\\env_LLMbook\\lib\\site-packages\\transformers\\generation\\utils.py:1375: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "100%|██████████| 1066/1066 [00:38<00:00, 27.40it/s]\n"
     ]
    }
   ],
   "source": [
    "# Run inference\n",
    "y_pred = []\n",
    "for output in tqdm(pipe(KeyDataset(data[\"test\"], \"t5\")), total=len(data[\"test\"])):\n",
    "    text = output[0][\"generated_text\"]\n",
    "    y_pred.append(0 if text == \"negative\" else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "Negative Review       0.83      0.84      0.83       533\n",
      "Positive Review       0.84      0.83      0.83       533\n",
      "\n",
      "       accuracy                           0.83      1066\n",
      "      macro avg       0.83      0.83      0.83      1066\n",
      "   weighted avg       0.83      0.83      0.83      1066\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_performance(data[\"test\"][\"label\"], y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_LLMbook",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
